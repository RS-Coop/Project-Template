#Experiment configuration file.

#PT Lightning trainer arguments.
#Documentation: https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html
#Comment out options you aren't using
train:
  accelerator: #str e.g. "gpu"
  devices: #int
  num_nodes: #int
  strategy: #str
  precision: #str
  enable_checkpointing: #bool
  check_val_every_n_epoch: #int
  default_root_dir: #str
  log_every_n_steps: #int
  enable_progress_bar: #bool
  profiler: #str
  max_epochs: #int
  max_steps: #int
  logger: #bool

#Model arguments
model:
  ckpt_path: #str, only use this if you want to continue training model from checkpoint
  learning_rate: #float

#PT LightningDataModule arguments
data:
  data_dir: #str
  batch_size: #int

#Extra arguments
extra:
  compute_stats: #bool
  early_stopping: #bool
